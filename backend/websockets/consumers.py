"""
WebSocket Chat Consumer - GerÃ§ek ZamanlÄ± Streaming.

Bu consumer adapter'lardan gelen her token'Ä± anÄ±nda client'a gÃ¶nderir.
Python 3.11+ native asyncio.timeout kullanÄ±r.

Ã–zellikler:
- ANLIK streaming (buffering yok)
- Otomatik adapter seÃ§imi (Gemini, HuggingFace, Ollama)
- AI Agents desteÄŸi (tool calling, reasoning)
- RAG desteÄŸi (dokÃ¼man arama)
- Rate limiting
- Keepalive ping/pong
- Graceful shutdown
- DetaylÄ± istatistikler
- Stop komutu desteÄŸi

Protocol:
    Client -> Server:
        {"modelId": "gemini-flash", "messages": [...]}
        {"modelId": "...", "messages": [...], "useAgent": true}  - Agent modu
        {"modelId": "...", "messages": [...], "useRag": true, "ragQuery": "..."}  - RAG modu
        "__STOP__"  - Streaming'i durdur
        "__PING__"  - Manuel ping
    
    Server -> Client:
        {"type": "connected", "ts": ...}  - BaÄŸlantÄ± onayÄ±
        {"delta": "token"}                - Her token anÄ±nda
        {"type": "thought", "content": "..."}  - Agent dÃ¼ÅŸÃ¼ncesi
        {"type": "tool_call", "tool": "...", "input": {...}}  - Tool Ã§aÄŸrÄ±sÄ±
        {"type": "tool_result", "tool": "...", "result": "..."}  - Tool sonucu
        {"type": "rag_context", "docs": [...]}  - RAG dokÃ¼manlarÄ±
        {"done": true, "stats": {...}}    - TamamlandÄ±
        {"error": "...", "detail": "..."}  - Hata
        {"stopped": true}                  - Durduruldu
        {"type": "ping", "ts": ...}       - Keepalive
"""

import json
import asyncio
import time
import logging
from typing import Optional, Dict, Any, List
from channels.generic.websocket import AsyncWebsocketConsumer

from backend.adapters import gemini as gem, huggingface as hf, ollama as ol

# Agent ve RAG imports (lazy loading)
_agent_executor = None
_rag_pipeline = None

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

logger = logging.getLogger('websockets.consumers')
logger.setLevel(logging.INFO)

if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)


# =============================================================================
# CONFIGURATION
# =============================================================================

# Keepalive ping interval (saniye)
PING_INTERVAL: int = 25

# Streaming timeout (saniye) - maksimum yanÄ±t sÃ¼resi
STREAM_TIMEOUT: int = 180

# Rate limiting
RATE_LIMIT_WINDOW: int = 5      # Saniye cinsinden pencere
RATE_LIMIT_MAX: int = 10        # Pencere iÃ§inde maksimum istek

# Mesaj boyutu limitleri
MAX_MESSAGE_SIZE: int = 100000  # 100KB
MAX_MESSAGES_COUNT: int = 500   # Tek istekte maksimum mesaj sayÄ±sÄ±


# =============================================================================
# ADAPTER REGISTRY
# =============================================================================

ADAPTERS: Dict[str, Any] = {
    'gemini': gem,
    'hf': hf,
    'ollama': ol,
}

# Model prefix -> Adapter mapping
MODEL_PREFIXES: Dict[str, str] = {
    'gemini': 'gemini',
    'hf': 'hf',
    'ollama': 'ollama',
}


def get_adapter(model_id: str):
    """
    Model ID'ye gÃ¶re uygun adapter'Ä± seÃ§.
    
    Args:
        model_id: Model tanÄ±mlayÄ±cÄ±sÄ± (Ã¶rn: "gemini-flash", "hf-mistral", "ollama:qwen")
    
    Returns:
        Adapter modÃ¼lÃ¼
    """
    if not model_id:
        logger.debug("No model_id provided, defaulting to Gemini")
        return gem
    
    model_lower = model_id.lower().strip()
    
    # Prefix-based seÃ§im
    for prefix, adapter_key in MODEL_PREFIXES.items():
        if model_lower.startswith(prefix):
            adapter = ADAPTERS.get(adapter_key, gem)
            logger.debug(f"Selected adapter '{adapter_key}' for model '{model_id}'")
            return adapter
    
    # VarsayÄ±lan: Gemini
    logger.debug(f"Unknown model prefix in '{model_id}', defaulting to Gemini")
    return gem


def get_agent_executor():
    """Lazy load agent executor."""
    global _agent_executor
    if _agent_executor is None:
        try:
            from backend.agents import AgentExecutor
            _agent_executor = AgentExecutor()
            logger.info("AgentExecutor loaded successfully")
        except ImportError as e:
            logger.warning(f"AgentExecutor not available: {e}")
            _agent_executor = False  # Mark as unavailable
    return _agent_executor if _agent_executor else None


def get_rag_pipeline():
    """Lazy load RAG pipeline - singleton embedding model kullanÄ±r."""
    global _rag_pipeline
    if _rag_pipeline is None:
        try:
            # Ã–nce embedding modelini preload et (singleton)
            from rag.pipelines import get_embedding_model
            get_embedding_model()  # Singleton'u initialize et
            
            from rag.pipelines import AsyncRAGPipeline
            _rag_pipeline = AsyncRAGPipeline()
            logger.info("RAGPipeline loaded successfully")
        except ImportError as e:
            logger.warning(f"RAGPipeline not available: {e}")
            _rag_pipeline = False  # Mark as unavailable
    return _rag_pipeline if _rag_pipeline else None


# =============================================================================
# CHAT CONSUMER
# =============================================================================

class ChatConsumer(AsyncWebsocketConsumer):
    """
    WebSocket Chat Consumer - ANLIK STREAMING.
    
    Her client baÄŸlantÄ±sÄ± iÃ§in ayrÄ± bir instance oluÅŸturulur.
    Streaming sÄ±rasÄ±nda her token anÄ±nda client'a gÃ¶nderilir.
    """
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # BaÄŸlantÄ± durumu
        self._connected: bool = False
        self._stop_flag: bool = False
        self._streaming: bool = False
        
        # Task referanslarÄ±
        self._ping_task: Optional[asyncio.Task] = None
        self._stream_task: Optional[asyncio.Task] = None
        
        # Rate limiting
        self._request_times: List[float] = []
        
        # Client bilgileri
        self._client_id: str = ''
        self._connect_time: float = 0
        self._total_requests: int = 0
        self._total_tokens: int = 0
    
    # =========================================================================
    # LIFECYCLE METHODS
    # =========================================================================
    
    async def connect(self):
        """
        WebSocket baÄŸlantÄ±sÄ±nÄ± kabul et ve baÅŸlat.
        """
        # Client ID oluÅŸtur
        client_info = self.scope.get('client', ['unknown', 0])
        self._client_id = f"{client_info[0]}:{client_info[1]}" if len(client_info) >= 2 else str(client_info[0])
        
        # Durumu gÃ¼ncelle
        self._connected = True
        self._stop_flag = False
        self._connect_time = time.time()
        
        # BaÄŸlantÄ±yÄ± kabul et
        await self.accept()
        
        # Keepalive task baÅŸlat
        self._ping_task = asyncio.create_task(self._keepalive_loop())
        
        logger.info(f"WebSocket connected: {self._client_id}")
        
        # HoÅŸ geldin mesajÄ± gÃ¶nder
        await self._send_json({
            'type': 'connected',
            'ts': int(time.time() * 1000),
            'client_id': self._client_id,
        })
    
    async def disconnect(self, code: int):
        """
        WebSocket baÄŸlantÄ±sÄ±nÄ± kapat ve temizle.
        
        Args:
            code: WebSocket kapatma kodu
        """
        self._connected = False
        self._stop_flag = True
        
        # Task'larÄ± iptal et
        if self._stream_task and not self._stream_task.done():
            self._stream_task.cancel()
            try:
                await self._stream_task
            except asyncio.CancelledError:
                pass
        
        if self._ping_task and not self._ping_task.done():
            self._ping_task.cancel()
            try:
                await self._ping_task
            except asyncio.CancelledError:
                pass
        
        # Ä°statistikleri logla
        session_duration = time.time() - self._connect_time
        logger.info(
            f"WebSocket disconnected: {self._client_id}, "
            f"code={code}, duration={session_duration:.1f}s, "
            f"requests={self._total_requests}, tokens={self._total_tokens}"
        )
    
    # =========================================================================
    # MESSAGE HANDLING
    # =========================================================================
    
    async def receive(self, text_data: Optional[str] = None, bytes_data: Optional[bytes] = None):
        """
        Client'tan gelen mesajlarÄ± iÅŸle.
        
        Args:
            text_data: Text formatÄ±nda mesaj
            bytes_data: Binary formatÄ±nda mesaj (desteklenmiyor)
        """
        if not text_data:
            return
        
        # Mesaj boyutu kontrolÃ¼
        if len(text_data) > MAX_MESSAGE_SIZE:
            await self._send_error('message_too_large', f'Maksimum mesaj boyutu: {MAX_MESSAGE_SIZE} byte')
            return
        
        text = text_data.strip()
        
        # === Ã–ZEL KOMUTLAR ===
        
        # Stop komutu
        if text == '__STOP__':
            await self._handle_stop()
            return
        
        # Ping komutu
        if text == '__PING__':
            await self._send_json({
                'type': 'pong',
                'ts': int(time.time() * 1000)
            })
            return
        
        # === JSON MESAJ ===
        
        try:
            payload = json.loads(text)
        except json.JSONDecodeError:
            await self._send_error('invalid_json', 'GeÃ§ersiz JSON formatÄ±')
            return
        
        # Rate limiting kontrolÃ¼
        if not self._check_rate_limit():
            await self._send_json({
                'error': 'rate_limited',
                'detail': f'Ã‡ok fazla istek. {RATE_LIMIT_WINDOW} saniye bekleyin.',
                'retry_after': RATE_LIMIT_WINDOW
            })
            return
        
        # Chat isteÄŸini iÅŸle
        await self._handle_chat(payload)
    
    async def _handle_stop(self):
        """Stop komutunu iÅŸle."""
        logger.debug(f"Stop command received: {self._client_id}")
        
        self._stop_flag = True
        
        if self._stream_task and not self._stream_task.done():
            self._stream_task.cancel()
        
        await self._send_json({'stopped': True})
    
    async def _handle_chat(self, payload: Dict[str, Any]):
        """
        Chat isteÄŸini iÅŸle ve streaming baÅŸlat.
        
        Args:
            payload: Chat isteÄŸi payload'Ä±
        """
        # Model ve mesajlarÄ± al
        model_id = payload.get('modelId') or payload.get('model') or 'gemini-flash'
        messages = payload.get('messages') or []
        
        # Agent ve RAG modlarÄ±
        use_agent = payload.get('useAgent', False)
        use_rag = payload.get('useRag', False)
        rag_query = payload.get('ragQuery', '')
        
        # Validasyon
        if not messages:
            await self._send_error('empty_messages', 'Mesaj listesi boÅŸ olamaz')
            return
        
        if len(messages) > MAX_MESSAGES_COUNT:
            await self._send_error('too_many_messages', f'Maksimum mesaj sayÄ±sÄ±: {MAX_MESSAGES_COUNT}')
            return
        
        # Ã–nceki stream'i iptal et
        if self._stream_task and not self._stream_task.done():
            logger.debug(f"Cancelling previous stream: {self._client_id}")
            self._stream_task.cancel()
            try:
                await self._stream_task
            except asyncio.CancelledError:
                pass
        
        # Yeni stream baÅŸlat
        self._stop_flag = False
        self._streaming = True
        self._total_requests += 1
        
        # Hangi modu kullanacaÄŸÄ±mÄ±zÄ± belirle
        if use_agent:
            self._stream_task = asyncio.create_task(
                self._agent_response(model_id, messages)
            )
        elif use_rag:
            self._stream_task = asyncio.create_task(
                self._rag_response(model_id, messages, rag_query)
            )
        else:
            self._stream_task = asyncio.create_task(
                self._stream_response(model_id, messages)
            )
    
    # =========================================================================
    # STREAMING - ANLIK
    # =========================================================================
    
    async def _stream_response(self, model_id: str, messages: List[Dict[str, Any]]):
        """
        Adapter'dan streaming yanÄ±t al ve ANLIK gÃ¶nder.
        
        Her token geldiÄŸinde hemen client'a iletilir.
        Buffering YOKTUR.
        
        Args:
            model_id: KullanÄ±lacak model ID
            messages: Mesaj listesi
        """
        adapter = get_adapter(model_id)
        start_time = time.time()
        chunk_count = 0
        total_chars = 0
        
        logger.info(f"Streaming started: client={self._client_id}, model={model_id}, messages={len(messages)}")
        
        try:
            # âœ… Python 3.11+ Native asyncio.timeout
            async with asyncio.timeout(STREAM_TIMEOUT):
                async for delta in adapter.stream(messages, model_id):
                    # Stop veya disconnect kontrolÃ¼
                    if self._stop_flag or not self._connected:
                        logger.debug(f"Streaming stopped: {self._client_id}")
                        await self._send_json({'stopped': True})
                        return
                    
                    # Delta varsa ANLIK gÃ¶nder
                    if delta:
                        chunk_count += 1
                        total_chars += len(delta)
                        
                        # === ANLIK GÃ–NDER - BUFFERING YOK ===
                        await self._send_json(
                            {'delta': delta},
                            ensure_ascii=False
                        )
            
            # Streaming baÅŸarÄ±yla tamamlandÄ±
            elapsed = time.time() - start_time
            self._total_tokens += chunk_count
            
            # TamamlandÄ± mesajÄ± gÃ¶nder
            await self._send_json({
                'done': True,
                'stats': {
                    'chunks': chunk_count,
                    'chars': total_chars,
                    'duration_ms': int(elapsed * 1000),
                    'model': model_id,
                    'tokens_per_second': round(chunk_count / elapsed, 1) if elapsed > 0 else 0,
                }
            })
            
            logger.info(
                f"Streaming completed: client={self._client_id}, "
                f"chunks={chunk_count}, chars={total_chars}, "
                f"duration={elapsed:.2f}s"
            )
            
        except asyncio.TimeoutError:
            logger.warning(f"Streaming timeout: {self._client_id}, model={model_id}")
            await self._send_json({
                'error': 'timeout',
                'detail': f'YanÄ±t {STREAM_TIMEOUT} saniye iÃ§inde tamamlanamadÄ±'
            })
            
        except asyncio.CancelledError:
            logger.debug(f"Streaming cancelled: {self._client_id}")
            # Sessizce Ã§Ä±k, client muhtemelen stop gÃ¶nderdi
            
        except Exception as e:
            logger.exception(f"Streaming error: {self._client_id}, error={e}")
            await self._send_json({
                'error': 'stream_failed',
                'detail': str(e)[:300]
            })
            
        finally:
            self._streaming = False
    
    # =========================================================================
    # KEEPALIVE
    # =========================================================================
    
    async def _keepalive_loop(self):
        """
        Periyodik ping gÃ¶nder - baÄŸlantÄ±yÄ± canlÄ± tut.
        
        WebSocket baÄŸlantÄ±larÄ± proxy'ler tarafÄ±ndan kapatÄ±labilir,
        bu ping'ler baÄŸlantÄ±nÄ±n aktif olduÄŸunu gÃ¶sterir.
        """
        try:
            while self._connected:
                await asyncio.sleep(PING_INTERVAL)
                
                if self._connected:
                    await self._send_json({
                        'type': 'ping',
                        'ts': int(time.time() * 1000)
                    })
                    
        except asyncio.CancelledError:
            pass
        except Exception as e:
            logger.debug(f"Keepalive error: {self._client_id}, error={e}")
    
    # =========================================================================
    # RATE LIMITING
    # =========================================================================
    
    def _check_rate_limit(self) -> bool:
        """
        Rate limiting kontrolÃ¼ yap.
        
        Returns:
            True: Ä°stek izinli
            False: Rate limit aÅŸÄ±ldÄ±
        """
        now = time.time()
        
        # Eski istekleri temizle
        self._request_times = [
            t for t in self._request_times 
            if now - t < RATE_LIMIT_WINDOW
        ]
        
        # Limit kontrolÃ¼
        if len(self._request_times) >= RATE_LIMIT_MAX:
            logger.warning(f"Rate limit exceeded: {self._client_id}")
            return False
        
        # Yeni isteÄŸi kaydet
        self._request_times.append(now)
        return True
    
    # =========================================================================
    # HELPER METHODS
    # =========================================================================
    
    async def _send_json(self, data: Dict[str, Any], ensure_ascii: bool = True):
        """
        JSON formatÄ±nda mesaj gÃ¶nder.
        
        Args:
            data: GÃ¶nderilecek dict
            ensure_ascii: ASCII olmayan karakterleri escape et
        """
        if not self._connected:
            return
        
        try:
            text = json.dumps(data, ensure_ascii=ensure_ascii)
            await self.send(text_data=text)
        except Exception as e:
            logger.debug(f"Send error: {self._client_id}, error={e}")
    
    async def _send_error(self, error_code: str, detail: str):
        """
        Hata mesajÄ± gÃ¶nder.
        
        Args:
            error_code: Hata kodu
            detail: Hata detayÄ±
        """
        await self._send_json({
            'error': error_code,
            'detail': detail,
            'ts': int(time.time() * 1000)
        })
    
    # =========================================================================
    # AGENT MODE - AI ile Tool Calling
    # =========================================================================
    
    async def _agent_response(self, model_id: str, messages: List[Dict[str, Any]]):
        """
        Agent modu - AI araÃ§larÄ± kullanarak yanÄ±t Ã¼retir.
        
        ReAct pattern: DÃ¼ÅŸÃ¼n -> AraÃ§ Kullan -> GÃ¶zlemle -> Tekrarla
        
        Args:
            model_id: KullanÄ±lacak model ID
            messages: Mesaj listesi
        """
        agent = get_agent_executor()
        if not agent:
            await self._send_error('agent_unavailable', 'Agent sistemi yÃ¼klenemedi')
            return
        
        adapter = get_adapter(model_id)
        start_time = time.time()
        
        # Son kullanÄ±cÄ± mesajÄ±nÄ± al
        user_message = ""
        for msg in reversed(messages):
            if msg.get('role') == 'user':
                user_message = msg.get('content', '')
                break
        
        if not user_message:
            await self._send_error('no_user_message', 'KullanÄ±cÄ± mesajÄ± bulunamadÄ±')
            return
        
        logger.info(f"Agent started: client={self._client_id}, model={model_id}")
        
        try:
            async with asyncio.timeout(STREAM_TIMEOUT):
                # Agent'Ä± Ã§alÄ±ÅŸtÄ±r (streaming callback ile)
                async def on_thought(thought: str):
                    if self._connected and not self._stop_flag:
                        await self._send_json({
                            'type': 'thought',
                            'content': thought
                        })
                
                async def on_tool_call(tool_name: str, tool_input: Dict[str, Any]):
                    if self._connected and not self._stop_flag:
                        await self._send_json({
                            'type': 'tool_call',
                            'tool': tool_name,
                            'input': tool_input
                        })
                
                async def on_tool_result(tool_name: str, result: str):
                    if self._connected and not self._stop_flag:
                        await self._send_json({
                            'type': 'tool_result',
                            'tool': tool_name,
                            'result': result[:1000]  # Truncate long results
                        })
                
                # Agent'Ä± Ã§alÄ±ÅŸtÄ±r
                result = await agent.run_async(
                    query=user_message,
                    model_id=model_id,
                    adapter=adapter,
                    on_thought=on_thought,
                    on_tool_call=on_tool_call,
                    on_tool_result=on_tool_result
                )
                
                # Final yanÄ±tÄ± stream et
                if result and self._connected and not self._stop_flag:
                    # YanÄ±tÄ± parÃ§alara bÃ¶l ve stream et
                    chunk_size = 20
                    for i in range(0, len(result), chunk_size):
                        if self._stop_flag or not self._connected:
                            break
                        chunk = result[i:i + chunk_size]
                        await self._send_json({'delta': chunk}, ensure_ascii=False)
                        await asyncio.sleep(0.01)  # Smooth streaming
                
                elapsed = time.time() - start_time
                
                await self._send_json({
                    'done': True,
                    'stats': {
                        'mode': 'agent',
                        'duration_ms': int(elapsed * 1000),
                        'model': model_id,
                    }
                })
                
                logger.info(f"Agent completed: client={self._client_id}, duration={elapsed:.2f}s")
                
        except asyncio.TimeoutError:
            await self._send_json({
                'error': 'timeout',
                'detail': f'Agent {STREAM_TIMEOUT} saniye iÃ§inde tamamlanamadÄ±'
            })
        except asyncio.CancelledError:
            logger.debug(f"Agent cancelled: {self._client_id}")
        except Exception as e:
            logger.exception(f"Agent error: {self._client_id}, error={e}")
            await self._send_json({
                'error': 'agent_failed',
                'detail': str(e)[:300]
            })
        finally:
            self._streaming = False
    
    # =========================================================================
    # RAG MODE - DokÃ¼man TabanlÄ± YanÄ±t
    # =========================================================================
    
    def _extract_page_numbers(self, text: str) -> List[int]:
        """
        Metinden sayfa numaralarÄ±nÄ± Ã§Ä±karÄ±r.
        
        Desteklenen formatlar:
        - "9. sayfayÄ± anlat" -> [9]
        - "sayfa 12'de ne var" -> [12]
        - "5 ve 10. sayfalarda" -> [5, 10]
        - "3-7 arasÄ±ndaki sayfalar" -> [3, 4, 5, 6, 7]
        - "sayfa 1,2,5" -> [1, 2, 5]
        - "9 ile 12 arasÄ±" -> [9, 10, 11, 12]
        
        Returns:
            Bulunan sayfa numaralarÄ±nÄ±n listesi
        """
        import re
        
        page_numbers = set()
        text_lower = text.lower()
        
        # Pattern 1: "X. sayfa" veya "X. sayfayÄ±" veya "X. sayfada" veya "X. sayfasÄ±nda"
        pattern1 = r'(\d+)\.\s*sayfa'
        for match in re.finditer(pattern1, text_lower):
            page_numbers.add(int(match.group(1)))
        
        # Pattern 2: "sayfa X" veya "sayfa X'de" veya "sayfa X'da"
        pattern2 = r'sayfa\s*(\d+)'
        for match in re.finditer(pattern2, text_lower):
            page_numbers.add(int(match.group(1)))
        
        # Pattern 3: "X ile Y arasÄ±" veya "X-Y arasÄ±" (aralÄ±k)
        pattern3 = r'(\d+)\s*(?:ile|-)\s*(\d+)\s*(?:aras[Ä±i]|sayfalar[Ä±i]?)'
        for match in re.finditer(pattern3, text_lower):
            start, end = int(match.group(1)), int(match.group(2))
            if start <= end <= start + 50:  # Max 50 sayfa aralÄ±k
                page_numbers.update(range(start, end + 1))
        
        # Pattern 4: "X-Y. sayfa" (aralÄ±k)
        pattern4 = r'(\d+)\s*-\s*(\d+)\.\s*sayfa'
        for match in re.finditer(pattern4, text_lower):
            start, end = int(match.group(1)), int(match.group(2))
            if start <= end <= start + 50:
                page_numbers.update(range(start, end + 1))
        
        # Pattern 5: "X, Y ve Z. sayfalar" (virgÃ¼llÃ¼ liste)
        pattern5 = r'(\d+(?:\s*,\s*\d+)+)\s*(?:ve|\.|,)?\s*(?:\d+)?\s*\.?\s*sayfa'
        for match in re.finditer(pattern5, text_lower):
            nums = re.findall(r'\d+', match.group(0))
            for n in nums:
                page_numbers.add(int(n))
        
        # Pattern 6: "X ve Y. sayfa" (iki sayfa)
        pattern6 = r'(\d+)\s+ve\s+(\d+)\s*\.?\s*sayfa'
        for match in re.finditer(pattern6, text_lower):
            page_numbers.add(int(match.group(1)))
            page_numbers.add(int(match.group(2)))
        
        # Pattern 7: "X. ve Y. sayfalar" (noktali format)
        pattern7 = r'(\d+)\.\s+ve\s+(\d+)\.\s*sayfa'
        for match in re.finditer(pattern7, text_lower):
            page_numbers.add(int(match.group(1)))
            page_numbers.add(int(match.group(2)))
        
        # Sayfa numaralarÄ±nÄ± sÄ±rala ve dÃ¶ndÃ¼r
        return sorted(list(page_numbers))
    
    async def _rag_response(self, model_id: str, messages: List[Dict[str, Any]], query: str):
        """
        RAG modu - DokÃ¼manlardan context alarak yanÄ±t Ã¼retir.
        
        Sayfa numarasÄ± iÃ§eren sorgularda (Ã¶rn: "9. sayfayÄ± anlat") doÄŸrudan
        o sayfanÄ±n iÃ§eriÄŸini getirir. DiÄŸer sorgularda semantik arama yapar.
        
        Args:
            model_id: KullanÄ±lacak model ID
            messages: Mesaj listesi
            query: RAG sorgusu (boÅŸsa son mesaj kullanÄ±lÄ±r)
        """
        rag = get_rag_pipeline()
        if not rag:
            await self._send_error('rag_unavailable', 'RAG sistemi yÃ¼klenemedi')
            return
        
        adapter = get_adapter(model_id)
        start_time = time.time()
        
        # Query'yi belirle
        if not query:
            for msg in reversed(messages):
                if msg.get('role') == 'user':
                    query = msg.get('content', '')
                    break
        
        if not query:
            await self._send_error('no_query', 'RAG sorgusu bulunamadÄ±')
            return
        
        logger.info(f"RAG started: client={self._client_id}, model={model_id}, query_len={len(query)}")
        
        try:
            async with asyncio.timeout(STREAM_TIMEOUT):
                # YÃ¼klÃ¼ dÃ¶kÃ¼manlarÄ±n listesini al (documents + pending)
                all_docs = rag.list_documents()
                
                # Ready ve processing dÃ¶kÃ¼manlarÄ± ayÄ±r
                ready_docs = [d for d in all_docs if d.get('status') == 'ready']
                pending_docs = [d for d in all_docs if d.get('status') != 'ready']
                
                doc_list_text = ""
                if all_docs:
                    doc_names = []
                    for doc in ready_docs:
                        doc_names.append(f"âœ… {doc.get('file_name', 'unknown')}")
                    for doc in pending_docs:
                        doc_names.append(f"â³ {doc.get('file_name', 'unknown')} (iÅŸleniyor...)")
                    doc_list_text = f"\n\nYÃ¼klÃ¼ dÃ¶kÃ¼manlar ({len(all_docs)} adet):\n" + "\n".join([f"  {name}" for name in doc_names])
                
                # ===== SAYFA BAZLI ARAMA DESTEÄÄ° =====
                # Sorgudan sayfa numaralarÄ±nÄ± Ã§Ä±kar
                requested_pages = self._extract_page_numbers(query)
                page_based_search = len(requested_pages) > 0
                
                docs = []
                search_mode = "semantic"  # veya "page-based"
                
                if page_based_search:
                    # Sayfa numarasÄ± belirtilmiÅŸ - doÄŸrudan o sayfalarÄ± getir
                    logger.info(f"Page-based search: pages={requested_pages}")
                    search_mode = "page-based"
                    
                    page_docs = await rag.get_pages_by_number(requested_pages)
                    
                    if page_docs:
                        docs = page_docs
                        logger.info(f"Found {len(docs)} chunks for pages {requested_pages}")
                    else:
                        # Sayfa bulunamadÄ±, semantik aramaya geri dÃ¶n
                        logger.info(f"No chunks found for pages {requested_pages}, falling back to semantic search")
                        docs = await rag.search_async(query, top_k=5)
                        search_mode = "semantic-fallback"
                else:
                    # Normal semantik arama
                    docs = await rag.search_async(query, top_k=5)
                
                # DokÃ¼manlarÄ± client'a gÃ¶nder
                if docs:
                    await self._send_json({
                        'type': 'rag_context',
                        'search_mode': search_mode,
                        'requested_pages': requested_pages if page_based_search else None,
                        'docs': [
                            {
                                'content': doc.get('text', '')[:500],
                                'source': doc.get('metadata', {}).get('file_name', 'unknown'),
                                'page': doc.get('metadata', {}).get('page_number', doc.get('page_number')),
                                'score': doc.get('score', 0)
                            }
                            for doc in docs
                        ]
                    })
                
                # Context'i mesajlara ekle (sayfa bilgisi ile)
                context_text = ""
                if docs:
                    context_parts = []
                    for doc in docs:
                        meta = doc.get('metadata', {})
                        file_name = meta.get('file_name', 'unknown')
                        page_num = meta.get('page_number', '')
                        total_pages = meta.get('total_pages', '')
                        page_info = f", Sayfa {page_num}/{total_pages}" if page_num else ""
                        
                        context_parts.append(
                            f"[Kaynak: {file_name}{page_info}]\n{doc.get('text', '')}"
                        )
                    context_text = "\n\n---\n\n".join(context_parts)
                
                # System mesajÄ± varsa gÃ¼ncelle, yoksa ekle
                system_msg = None
                for i, msg in enumerate(messages):
                    if msg.get('role') == 'system':
                        system_msg = msg
                        break
                
                # DÃ¶kÃ¼man listesini oluÅŸtur
                doc_list_items = []
                for doc in ready_docs:
                    doc_list_items.append(f"âœ… {doc.get('file_name', 'unknown')} (hazÄ±r)")
                for doc in pending_docs:
                    doc_list_items.append(f"â³ {doc.get('file_name', 'unknown')} (iÅŸleniyor...)")
                
                doc_list_str = chr(10).join(doc_list_items) if doc_list_items else "(HenÃ¼z dÃ¶kÃ¼man yÃ¼klenmemiÅŸ)"
                
                # Sayfa bazlÄ± arama bilgisi
                page_search_info = ""
                if page_based_search:
                    page_search_info = f"""
ğŸ” SAYFA BAZLI ARAMA YAPILDI
Ä°stenen sayfalar: {requested_pages}
Bulunan chunk sayÄ±sÄ±: {len(docs)}
Arama modu: {search_mode}
"""
                
                rag_instruction = f"""Sen bir RAG (Retrieval Augmented Generation) asistanÄ±sÄ±n.
KullanÄ±cÄ±nÄ±n yÃ¼klediÄŸi dÃ¶kÃ¼manlarÄ± kullanarak sorularÄ±nÄ± yanÄ±tlÄ±yorsun.

=== YÃœKLÃœ DÃ–KÃœMANLAR ({len(all_docs)} adet) ===
{doc_list_str}
=== YÃœKLÃœ DÃ–KÃœMANLAR SONU ===
{page_search_info}
Ã–NEMLÄ°: "â³ iÅŸleniyor" olan dÃ¶kÃ¼manlar henÃ¼z aranabilir deÄŸil. KullanÄ±cÄ± bu dÃ¶kÃ¼manlar hakkÄ±nda soru sorarsa, "Bu dÃ¶kÃ¼man henÃ¼z iÅŸleniyor, lÃ¼tfen bekleyin" de.

KullanÄ±cÄ± sana dÃ¶kÃ¼manlar hakkÄ±nda sorular sorabilir:
- "Hangi dÃ¶kÃ¼manlarÄ± yÃ¼kledim?" â†’ YukarÄ±daki dÃ¶kÃ¼man listesini AYNEN gÃ¶ster
- "X. sayfayÄ± anlat" â†’ AÅŸaÄŸÄ±da o sayfanÄ±n iÃ§eriÄŸi var, onu kullanarak anlat
- "Y sayfasÄ±nda ne yazÄ±yor?" â†’ O sayfadaki iÃ§eriÄŸi bul ve yanÄ±tla
- "Bu konuda ne biliyorsun?" â†’ DÃ¶kÃ¼manlardan ilgili bilgileri bul

{"ğŸ“– AÅŸaÄŸÄ±da, kullanÄ±cÄ±nÄ±n istediÄŸi " + (f"SAYFA {requested_pages} iÃ§eriÄŸi var:" if page_based_search else "sorusuyla ilgili bulunan dÃ¶kÃ¼man parÃ§alarÄ± var:") if docs else "Bu sorguyla ilgili dÃ¶kÃ¼man bulunamadÄ± (belki dÃ¶kÃ¼manlar henÃ¼z iÅŸleniyor)."}

=== Ä°LGÄ°LÄ° DÃ–KÃœMAN Ä°Ã‡ERÄ°ÄÄ° ===
{context_text if context_text else "(EÅŸleÅŸen iÃ§erik bulunamadÄ±)"}
=== DÃ–KÃœMAN Ä°Ã‡ERÄ°ÄÄ° SONU ===

Kurallar:
1. KullanÄ±cÄ± "hangi dÃ¶kÃ¼manlarÄ± yÃ¼kledim" derse, YÃœKLÃœ DÃ–KÃœMANLAR listesini AYNEN gÃ¶ster
2. YanÄ±tlarÄ±nÄ± SADECE yÃ¼klenen ve hazÄ±r olan (âœ…) dokÃ¼manlara dayandÄ±r
3. Her yanÄ±tta kaynak dÃ¶kÃ¼man adÄ±nÄ± ve sayfa numarasÄ±nÄ± belirt (varsa)
4. EÄŸer sorulan bilgi dokÃ¼manlarda yoksa veya dÃ¶kÃ¼manlar iÅŸleniyorsa, bunu aÃ§Ä±kÃ§a sÃ¶yle
5. KullanÄ±cÄ± sayfa numarasÄ± sorduÄŸunda, yukarÄ±da o sayfanÄ±n iÃ§eriÄŸi verilmiÅŸse, onu detaylÄ±ca anlat
6. Sayfa iÃ§eriÄŸi yoksa "Bu sayfa numarasÄ±na ait iÃ§erik bulunamadÄ±" de
"""
                
                if system_msg:
                    system_msg['content'] = system_msg['content'] + "\n\n" + rag_instruction
                else:
                    messages.insert(0, {'role': 'system', 'content': rag_instruction})
                
                # Normal streaming yap
                chunk_count = 0
                total_chars = 0
                
                async for delta in adapter.stream(messages, model_id):
                    if self._stop_flag or not self._connected:
                        await self._send_json({'stopped': True})
                        return
                    
                    if delta:
                        chunk_count += 1
                        total_chars += len(delta)
                        await self._send_json({'delta': delta}, ensure_ascii=False)
                
                elapsed = time.time() - start_time
                
                await self._send_json({
                    'done': True,
                    'stats': {
                        'mode': 'rag',
                        'search_mode': search_mode,
                        'requested_pages': requested_pages if page_based_search else None,
                        'chunks': chunk_count,
                        'chars': total_chars,
                        'docs_found': len(docs) if docs else 0,
                        'duration_ms': int(elapsed * 1000),
                        'model': model_id,
                    }
                })
                
                logger.info(
                    f"RAG completed: client={self._client_id}, "
                    f"docs={len(docs) if docs else 0}, duration={elapsed:.2f}s"
                )
                
        except asyncio.TimeoutError:
            await self._send_json({
                'error': 'timeout',
                'detail': f'RAG {STREAM_TIMEOUT} saniye iÃ§inde tamamlanamadÄ±'
            })
        except asyncio.CancelledError:
            logger.debug(f"RAG cancelled: {self._client_id}")
        except Exception as e:
            logger.exception(f"RAG error: {self._client_id}, error={e}")
            await self._send_json({
                'error': 'rag_failed',
                'detail': str(e)[:300]
            })
        finally:
            self._streaming = False


# =============================================================================
# MODULE EXPORTS
# =============================================================================

__all__ = ['ChatConsumer']