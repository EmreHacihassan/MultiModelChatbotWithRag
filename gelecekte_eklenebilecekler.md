# ğŸš€ MyChatbot - Gelecekte Eklenebilecek Ã–zellikler

Bu dÃ¶kÃ¼man, RAG sistemi iÃ§in planlanan ileri dÃ¼zey Ã¶zellikleri ve uygulama detaylarÄ±nÄ± iÃ§erir.

---

## ğŸ“‹ Ã–zellik Listesi

| # | Ã–zellik | Zorluk | Etki | Durum |
|---|---------|--------|------|-------|
| 1 | Multi-Modal RAG (GÃ¶rsel + Metin) | â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 2 | Conversational RAG (BaÄŸlam HatÄ±rlama) | â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 3 | Table QA (Tablo Sorgulama) | â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 4 | Ã‡oklu DÃ¶kÃ¼man KarÅŸÄ±laÅŸtÄ±rma | â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 5 | Otomatik Ã–zet ve Rapor | â­ | ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 6 | Semantik Kod Arama | â­â­ | ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 7 | Web URL'den DÃ¶kÃ¼man Ekleme | â­â­ | ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 8 | Zaman BazlÄ± Sorgulama | â­â­ | ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 9 | Kaynak GÃ¼venilirlik Skoru | â­â­ | ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |
| 10 | Otomatik Soru Ã–nerisi | â­ | ğŸ”¥ğŸ”¥ | ğŸ“‹ PlanlandÄ± |

---

## 1. ğŸ–¼ï¸ Multi-Modal RAG (GÃ¶rsel + Metin)

### AÃ§Ä±klama
PDF'lerdeki grafik, tablo, resim ve diyagramlarÄ± da anlayabilen sistem. Sadece metin deÄŸil, gÃ¶rsel iÃ§erikleri de analiz edebilir.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "Bu PDF'deki pasta grafiÄŸinde en bÃ¼yÃ¼k dilim hangi kategori?"
AI: "Grafikteki en bÃ¼yÃ¼k dilim %45 ile 'Teknoloji' kategorisi. Ä°kinci sÄ±rada %30 ile 'SaÄŸlÄ±k' var."

KullanÄ±cÄ±: "Åemadaki akÄ±ÅŸ diyagramÄ±nÄ± aÃ§Ä±kla"
AI: "Diyagramda 5 adÄ±mlÄ± bir sÃ¼reÃ§ var: 1. BaÅŸvuru â†’ 2. Ä°nceleme â†’ 3. Onay â†’ ..."
```

### Teknik Gereksinimler
- **Model**: GPT-4V, Gemini Pro Vision, veya LLaVA
- **KÃ¼tÃ¼phaneler**: `pdf2image`, `pytesseract`, `Pillow`
- **Ek Depolama**: GÃ¶rsel embedding'ler iÃ§in CLIP modeli

### Uygulama AdÄ±mlarÄ±
```python
# 1. PDF'den gÃ¶rsel Ã§Ä±karma
from pdf2image import convert_from_path

def extract_images_from_pdf(pdf_path):
    images = convert_from_path(pdf_path)
    image_data = []
    for i, img in enumerate(images):
        # OCR ile metin Ã§Ä±kar
        text = pytesseract.image_to_string(img)
        # GÃ¶rsel embedding oluÅŸtur
        embedding = clip_model.encode(img)
        image_data.append({
            'page': i + 1,
            'image': img,
            'ocr_text': text,
            'embedding': embedding
        })
    return image_data

# 2. GÃ¶rsel arama
def search_images(query, image_embeddings):
    query_embedding = clip_model.encode(query)
    similarities = cosine_similarity(query_embedding, image_embeddings)
    return sorted(similarities, reverse=True)[:5]
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 2-3 gÃ¼n
- Test: 1 gÃ¼n

---

## 2. ğŸ’¬ Conversational RAG (BaÄŸlam HatÄ±rlama)

### AÃ§Ä±klama
Ã–nceki sorularÄ± ve cevaplarÄ± hatÄ±rlayarak takip sorularÄ±na doÄŸru cevap verebilen sistem. "O", "bu", "onun" gibi referanslarÄ± Ã§Ã¶zebilir.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "Bu kitapta Ahmet kim?"
AI: "Ahmet, romanÄ±n ana karakteri ve bir yazÄ±lÄ±m mÃ¼hendisi. Ä°stanbul'da yaÅŸÄ±yor."

KullanÄ±cÄ±: "Peki onun karÄ±sÄ± ne iÅŸ yapÄ±yor?"  â† "onun" = Ahmet
AI: "Ahmet'in karÄ±sÄ± AyÅŸe, bir ilkokul Ã¶ÄŸretmeni olarak Ã§alÄ±ÅŸÄ±yor."

KullanÄ±cÄ±: "Ã‡ocuklarÄ± var mÄ±?"  â† Hala Ahmet ve AyÅŸe'den bahsediyor
AI: "Evet, Ahmet ve AyÅŸe'nin iki Ã§ocuÄŸu var: 8 yaÅŸÄ±nda Elif ve 5 yaÅŸÄ±nda Can."
```

### Teknik Gereksinimler
- **Conversation Memory**: Son N mesajÄ± context'e ekle
- **Coreference Resolution**: "o", "bu" gibi referanslarÄ± Ã§Ã¶z
- **Query Rewriting**: Eksik baÄŸlamÄ± tamamla

### Uygulama AdÄ±mlarÄ±
```python
class ConversationalRAG:
    def __init__(self, rag_pipeline, memory_size=10):
        self.rag = rag_pipeline
        self.memory_size = memory_size
        self.conversation_history = []
    
    def rewrite_query(self, query: str, history: list) -> str:
        """BaÄŸlamÄ± tamamlayarak sorguyu yeniden yaz."""
        if not history:
            return query
        
        # Son konuÅŸmalarÄ± context olarak kullan
        context = "\n".join([
            f"KullanÄ±cÄ±: {h['user']}\nAI: {h['assistant']}"
            for h in history[-3:]
        ])
        
        rewrite_prompt = f"""
        Ã–nceki konuÅŸma:
        {context}
        
        Yeni soru: {query}
        
        Bu soruyu, Ã¶nceki konuÅŸma baÄŸlamÄ±nÄ± da iÃ§erecek ÅŸekilde yeniden yaz.
        Ã–rnek: "onun karÄ±sÄ±" â†’ "Ahmet'in karÄ±sÄ±"
        """
        
        return llm.complete(rewrite_prompt)
    
    def chat(self, query: str) -> str:
        # 1. Sorguyu yeniden yaz
        rewritten = self.rewrite_query(query, self.conversation_history)
        
        # 2. RAG aramasÄ± yap
        docs = self.rag.search(rewritten)
        
        # 3. Cevap Ã¼ret (conversation history ile)
        response = self.generate_response(query, docs, self.conversation_history)
        
        # 4. History'ye ekle
        self.conversation_history.append({
            'user': query,
            'assistant': response,
            'rewritten_query': rewritten
        })
        
        # Memory limit
        if len(self.conversation_history) > self.memory_size:
            self.conversation_history.pop(0)
        
        return response
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 1-2 gÃ¼n
- Test: 0.5 gÃ¼n

---

## 3. ğŸ“Š Table QA (Tablo Sorgulama)

### AÃ§Ä±klama
PDF ve Excel'deki tablolarÄ± SQL benzeri doÄŸal dil sorgularÄ± ile sorgulama. SayÄ±sal analiz, filtreleme, toplama iÅŸlemleri.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "2023 yÄ±lÄ±nda en Ã§ok satÄ±ÅŸ yapan Ã¼rÃ¼n hangisi?"
AI: "Tabloya gÃ¶re 2023'te en Ã§ok satan Ã¼rÃ¼n 'Laptop Pro X' (15,230 adet). 
     Ä°kinci sÄ±rada 'Tablet Y' (12,100 adet) var."

KullanÄ±cÄ±: "Toplam satÄ±ÅŸ geliri ne kadar?"
AI: "2023 yÄ±lÄ± toplam satÄ±ÅŸ geliri: 4,523,000 TL"

KullanÄ±cÄ±: "SatÄ±ÅŸlarÄ± aya gÃ¶re karÅŸÄ±laÅŸtÄ±r"
AI: "En yÃ¼ksek satÄ±ÅŸ AralÄ±k ayÄ±nda (523,000 TL), en dÃ¼ÅŸÃ¼k Åubat'ta (212,000 TL)."
```

### Teknik Gereksinimler
- **KÃ¼tÃ¼phaneler**: `pandas`, `tabula-py`, `openpyxl`
- **Tablo Ã‡Ä±karma**: PDF'den tablo algÄ±lama
- **NL2SQL**: DoÄŸal dili SQL'e Ã§evirme (veya Pandas query)

### Uygulama AdÄ±mlarÄ±
```python
import pandas as pd
import tabula

class TableQA:
    def __init__(self):
        self.tables = {}  # file_id -> list of DataFrames
    
    def extract_tables_from_pdf(self, pdf_path: str) -> list:
        """PDF'den tablolarÄ± Ã§Ä±kar."""
        tables = tabula.read_pdf(pdf_path, pages='all')
        return tables
    
    def extract_tables_from_excel(self, excel_path: str) -> list:
        """Excel'den tablolarÄ± Ã§Ä±kar."""
        xlsx = pd.ExcelFile(excel_path)
        tables = [pd.read_excel(xlsx, sheet) for sheet in xlsx.sheet_names]
        return tables
    
    def query_table(self, table: pd.DataFrame, query: str) -> str:
        """DoÄŸal dil sorgusu ile tabloyu sorgula."""
        # Tablo ÅŸemasÄ±nÄ± LLM'e ver
        schema = f"SÃ¼tunlar: {list(table.columns)}\nSatÄ±r sayÄ±sÄ±: {len(table)}"
        
        # LLM'den Pandas kodu iste
        code_prompt = f"""
        Tablo ÅŸemasÄ±: {schema}
        Ä°lk 3 satÄ±r: {table.head(3).to_string()}
        
        KullanÄ±cÄ± sorusu: {query}
        
        Bu soruyu cevaplamak iÃ§in gerekli Pandas kodunu yaz.
        Sadece kodu yaz, aÃ§Ä±klama yazma.
        DeÄŸiÅŸken adÄ± 'df' olsun.
        """
        
        pandas_code = llm.complete(code_prompt)
        
        # Kodu gÃ¼venli ÅŸekilde Ã§alÄ±ÅŸtÄ±r
        result = self.safe_execute(pandas_code, {'df': table})
        
        return result
    
    def safe_execute(self, code: str, variables: dict):
        """Pandas kodunu gÃ¼venli ÅŸekilde Ã§alÄ±ÅŸtÄ±r."""
        allowed_modules = {'pd': pd, 'np': np}
        local_vars = {**allowed_modules, **variables}
        
        try:
            exec(code, {"__builtins__": {}}, local_vars)
            return local_vars.get('result', 'SonuÃ§ bulunamadÄ±')
        except Exception as e:
            return f"Sorgu Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±: {e}"
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 2-3 gÃ¼n
- Test: 1 gÃ¼n

---

## 4. ğŸ”— Ã‡oklu DÃ¶kÃ¼man KarÅŸÄ±laÅŸtÄ±rma

### AÃ§Ä±klama
Birden fazla dÃ¶kÃ¼manÄ± karÅŸÄ±laÅŸtÄ±rÄ±p farklÄ±lÄ±klarÄ±, benzerlikleri ve Ã§eliÅŸkileri tespit etme.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "Bu iki sÃ¶zleÅŸme arasÄ±ndaki farklar neler?"
AI: "Ä°ki sÃ¶zleÅŸme arasÄ±ndaki temel farklar:

1. **SÃ¼re**: SÃ¶zleÅŸme A: 12 ay, SÃ¶zleÅŸme B: 24 ay
2. **Fiyat**: A: 10,000 TL/ay, B: 8,500 TL/ay
3. **Fesih**: A: 30 gÃ¼n Ã¶nceden bildirim, B: 60 gÃ¼n
4. **Ceza**: A: 2 aylÄ±k Ã¼cret, B: 3 aylÄ±k Ã¼cret

âš ï¸ Ã‡eliÅŸki: A'da 'tek taraflÄ± fesih yok' yazÄ±yor, B'de 'tek taraflÄ± fesih mÃ¼mkÃ¼n'."

KullanÄ±cÄ±: "Hangi sÃ¶zleÅŸme daha avantajlÄ±?"
AI: "KÄ±sa vadede A daha avantajlÄ± (daha esnek fesih), uzun vadede B daha avantajlÄ± (daha dÃ¼ÅŸÃ¼k aylÄ±k Ã¼cret)."
```

### Teknik Gereksinimler
- **Diff AlgoritmasÄ±**: Metinler arasÄ± fark bulma
- **Semantic Similarity**: Benzer bÃ¶lÃ¼mleri eÅŸleÅŸtirme
- **Contradiction Detection**: Ã‡eliÅŸkileri tespit etme

### Uygulama AdÄ±mlarÄ±
```python
class DocumentComparator:
    def __init__(self, rag_pipeline):
        self.rag = rag_pipeline
    
    def compare_documents(self, doc_ids: list, aspects: list = None) -> dict:
        """Ä°ki veya daha fazla dÃ¶kÃ¼manÄ± karÅŸÄ±laÅŸtÄ±r."""
        
        # VarsayÄ±lan karÅŸÄ±laÅŸtÄ±rma boyutlarÄ±
        if aspects is None:
            aspects = ['sÃ¼re', 'fiyat', 'koÅŸullar', 'yÃ¼kÃ¼mlÃ¼lÃ¼kler', 'fesih']
        
        results = {
            'similarities': [],
            'differences': [],
            'contradictions': []
        }
        
        for aspect in aspects:
            # Her dÃ¶kÃ¼man iÃ§in ilgili bÃ¶lÃ¼mÃ¼ bul
            doc_contents = {}
            for doc_id in doc_ids:
                chunks = self.rag.search(
                    query=aspect,
                    filter={'document_id': doc_id}
                )
                doc_contents[doc_id] = chunks
            
            # KarÅŸÄ±laÅŸtÄ±r
            comparison = self.compare_aspect(aspect, doc_contents)
            
            if comparison['type'] == 'similar':
                results['similarities'].append(comparison)
            elif comparison['type'] == 'different':
                results['differences'].append(comparison)
            elif comparison['type'] == 'contradiction':
                results['contradictions'].append(comparison)
        
        return results
    
    def compare_aspect(self, aspect: str, doc_contents: dict) -> dict:
        """Belirli bir boyutta karÅŸÄ±laÅŸtÄ±rma yap."""
        prompt = f"""
        AÅŸaÄŸÄ±daki dÃ¶kÃ¼man bÃ¶lÃ¼mlerini '{aspect}' aÃ§Ä±sÄ±ndan karÅŸÄ±laÅŸtÄ±r.
        
        DÃ¶kÃ¼manlar:
        {json.dumps(doc_contents, ensure_ascii=False, indent=2)}
        
        Ã‡Ä±ktÄ± formatÄ±:
        - type: "similar" | "different" | "contradiction"
        - aspect: karÅŸÄ±laÅŸtÄ±rma boyutu
        - details: her dÃ¶kÃ¼man iÃ§in detay
        - summary: Ã¶zet karÅŸÄ±laÅŸtÄ±rma
        """
        
        return llm.complete(prompt, output_format='json')
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 2 gÃ¼n
- Test: 1 gÃ¼n

---

## 5. ğŸ“ Otomatik Ã–zet ve Rapor

### AÃ§Ä±klama
DÃ¶kÃ¼manlardan otomatik Ã¶zet, madde iÅŸaretli liste, executive summary veya detaylÄ± rapor oluÅŸturma.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "Bu 50 sayfalÄ±k raporu 5 maddede Ã¶zetle"
AI: "ğŸ“‹ Rapor Ã–zeti:
1. Åirket 2023'te %20 bÃ¼yÃ¼me kaydetti
2. Yeni Ã¼rÃ¼n lansmanÄ± Q2'de gerÃ§ekleÅŸti
3. MÃ¼ÅŸteri memnuniyeti %85'e yÃ¼kseldi
4. Operasyonel maliyetler %10 dÃ¼ÅŸtÃ¼
5. 2024 hedefi: UluslararasÄ± pazara aÃ§Ä±lÄ±m"

KullanÄ±cÄ±: "DetaylÄ± bir executive summary yaz"
AI: "## Executive Summary
### Genel BakÄ±ÅŸ
[DetaylÄ± Ã¶zet...]

### Finansal Performans
[Tablo ve grafikler...]

### Ã–neriler
[Aksiyon maddeleri...]"
```

### Teknik Gereksinimler
- **Summarization**: Extractive veya Abstractive Ã¶zet
- **Template Engine**: FarklÄ± rapor formatlarÄ±
- **Section Detection**: BÃ¶lÃ¼m baÅŸlÄ±klarÄ±nÄ± algÄ±lama

### Uygulama AdÄ±mlarÄ±
```python
class DocumentSummarizer:
    TEMPLATES = {
        'bullet_points': "DÃ¶kÃ¼manÄ± {count} madde ile Ã¶zetle.",
        'executive_summary': "YÃ¶netici Ã¶zeti formatÄ±nda detaylÄ± Ã¶zet yaz.",
        'key_findings': "Ana bulgular ve sonuÃ§larÄ± listele.",
        'action_items': "Gerekli aksiyon maddelerini Ã§Ä±kar.",
    }
    
    def __init__(self, rag_pipeline):
        self.rag = rag_pipeline
    
    def summarize(self, doc_id: str, template: str = 'bullet_points', **kwargs) -> str:
        """DÃ¶kÃ¼manÄ± belirtilen formatta Ã¶zetle."""
        
        # TÃ¼m dÃ¶kÃ¼man iÃ§eriÄŸini al
        chunks = self.rag.get_all_chunks(doc_id)
        full_text = "\n".join([c['text'] for c in chunks])
        
        # Ã‡ok uzunsa hierarchical summarization
        if len(full_text) > 10000:
            return self.hierarchical_summarize(chunks, template, **kwargs)
        
        prompt = self.TEMPLATES[template].format(**kwargs)
        
        return llm.complete(f"{prompt}\n\nDÃ¶kÃ¼man:\n{full_text}")
    
    def hierarchical_summarize(self, chunks: list, template: str, **kwargs) -> str:
        """BÃ¼yÃ¼k dÃ¶kÃ¼manlar iÃ§in kademeli Ã¶zet."""
        
        # 1. Her chunk'Ä± Ã¶zetle
        chunk_summaries = []
        for chunk in chunks:
            summary = llm.complete(f"KÄ±saca Ã¶zetle:\n{chunk['text']}")
            chunk_summaries.append(summary)
        
        # 2. Ã–zetleri birleÅŸtir ve son Ã¶zeti yap
        combined = "\n".join(chunk_summaries)
        final_prompt = self.TEMPLATES[template].format(**kwargs)
        
        return llm.complete(f"{final_prompt}\n\nÄ°Ã§erik:\n{combined}")
    
    def generate_report(self, doc_ids: list, report_type: str = 'comprehensive') -> str:
        """Birden fazla dÃ¶kÃ¼man iÃ§in rapor oluÅŸtur."""
        
        sections = []
        
        for doc_id in doc_ids:
            doc_info = self.rag.get_document_info(doc_id)
            summary = self.summarize(doc_id, 'executive_summary')
            
            sections.append({
                'title': doc_info['file_name'],
                'summary': summary
            })
        
        # Rapor ÅŸablonu
        report = f"""
# ğŸ“Š DÃ¶kÃ¼man Analiz Raporu
Tarih: {datetime.now().strftime('%d.%m.%Y')}
Analiz edilen dÃ¶kÃ¼man sayÄ±sÄ±: {len(doc_ids)}

---

"""
        for section in sections:
            report += f"## {section['title']}\n{section['summary']}\n\n---\n\n"
        
        return report
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 1 gÃ¼n
- Test: 0.5 gÃ¼n

---

## 6. ğŸ” Semantik Kod Arama

### AÃ§Ä±klama
Kod dosyalarÄ±nÄ± (Python, JavaScript, vb.) yÃ¼kleyip doÄŸal dil ile arama yapabilme. Fonksiyon, class ve metotlarÄ± anlama.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "KullanÄ±cÄ± authentication yapan fonksiyon hangisi?"
AI: "auth/views.py dosyasÄ±ndaki `login_user()` fonksiyonu kullanÄ±cÄ± doÄŸrulamasÄ± yapÄ±yor:

```python
def login_user(request):
    # ... kod ...
```

AyrÄ±ca `verify_token()` fonksiyonu da ilgili."

KullanÄ±cÄ±: "Bu fonksiyonu kullanan yerler neresi?"
AI: "login_user() fonksiyonu 3 yerde kullanÄ±lÄ±yor:
1. api/routes.py:45 - /login endpoint'i
2. middleware/auth.py:23 - session kontrolÃ¼
3. tests/test_auth.py:12 - unit test"
```

### Teknik Gereksinimler
- **Code Parser**: AST parsing (tree-sitter)
- **Code Embeddings**: CodeBERT veya StarCoder
- **Symbol Extraction**: Fonksiyon, class, import Ã§Ä±karma

### Uygulama AdÄ±mlarÄ±
```python
import ast
from tree_sitter import Language, Parser

class CodeSearchEngine:
    SUPPORTED_LANGUAGES = ['python', 'javascript', 'typescript']
    
    def __init__(self, embedding_model):
        self.embedding_model = embedding_model
        self.code_index = {}
    
    def index_code_file(self, file_path: str) -> list:
        """Kod dosyasÄ±nÄ± indexle."""
        
        with open(file_path, 'r') as f:
            code = f.read()
        
        # Dile gÃ¶re parse et
        language = self.detect_language(file_path)
        symbols = self.extract_symbols(code, language)
        
        indexed = []
        for symbol in symbols:
            embedding = self.embedding_model.encode(
                f"{symbol['type']} {symbol['name']}: {symbol['docstring']}\n{symbol['code']}"
            )
            
            indexed.append({
                'file': file_path,
                'type': symbol['type'],  # function, class, method
                'name': symbol['name'],
                'line': symbol['line'],
                'code': symbol['code'],
                'docstring': symbol['docstring'],
                'embedding': embedding
            })
        
        return indexed
    
    def extract_symbols(self, code: str, language: str) -> list:
        """Koddan sembolleri Ã§Ä±kar."""
        
        if language == 'python':
            return self.extract_python_symbols(code)
        elif language in ['javascript', 'typescript']:
            return self.extract_js_symbols(code)
    
    def extract_python_symbols(self, code: str) -> list:
        """Python kodundan fonksiyon ve class'larÄ± Ã§Ä±kar."""
        
        tree = ast.parse(code)
        symbols = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                symbols.append({
                    'type': 'function',
                    'name': node.name,
                    'line': node.lineno,
                    'code': ast.get_source_segment(code, node),
                    'docstring': ast.get_docstring(node) or ''
                })
            elif isinstance(node, ast.ClassDef):
                symbols.append({
                    'type': 'class',
                    'name': node.name,
                    'line': node.lineno,
                    'code': ast.get_source_segment(code, node),
                    'docstring': ast.get_docstring(node) or ''
                })
        
        return symbols
    
    def search_code(self, query: str, top_k: int = 5) -> list:
        """DoÄŸal dil ile kod ara."""
        
        query_embedding = self.embedding_model.encode(query)
        
        results = []
        for symbol in self.code_index.values():
            similarity = cosine_similarity(query_embedding, symbol['embedding'])
            results.append({**symbol, 'score': similarity})
        
        return sorted(results, key=lambda x: x['score'], reverse=True)[:top_k]
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 2-3 gÃ¼n
- Test: 1 gÃ¼n

---

## 7. ğŸŒ Web URL'den DÃ¶kÃ¼man Ekleme

### AÃ§Ä±klama
URL vererek web sayfasÄ±nÄ± veya online dÃ¶kÃ¼manÄ± RAG sistemine ekleme. HTML parsing, PDF download, sitemap crawling.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "https://docs.python.org/3/tutorial adresini ekle"
AI: "âœ… Python Tutorial sayfasÄ± eklendi!
     - 45 sayfa iÅŸlendi
     - 230 metin parÃ§asÄ± oluÅŸturuldu
     - HazÄ±r sorulabilir!"

KullanÄ±cÄ±: "Python'da list comprehension nasÄ±l kullanÄ±lÄ±r?"
AI: "[Tutorial'dan] List comprehension ÅŸÃ¶yle kullanÄ±lÄ±r:
     squares = [x**2 for x in range(10)]
     ..."
```

### Teknik Gereksinimler
- **Web Scraping**: `requests`, `BeautifulSoup`, `trafilatura`
- **PDF Download**: URL'den PDF indirme
- **Rate Limiting**: Siteleri yormamak iÃ§in gecikme
- **Robots.txt**: Kurallara uyum

### Uygulama AdÄ±mlarÄ±
```python
import requests
from bs4 import BeautifulSoup
import trafilatura
from urllib.parse import urljoin, urlparse

class WebDocumentLoader:
    def __init__(self, rag_pipeline):
        self.rag = rag_pipeline
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'MyChatbot/1.0 (RAG Document Indexer)'
        })
    
    def load_url(self, url: str, crawl_depth: int = 0) -> dict:
        """URL'den iÃ§erik yÃ¼kle."""
        
        # URL tipini belirle
        if url.endswith('.pdf'):
            return self.load_pdf_url(url)
        else:
            return self.load_html_url(url, crawl_depth)
    
    def load_html_url(self, url: str, crawl_depth: int = 0) -> dict:
        """HTML sayfasÄ±nÄ± yÃ¼kle ve iÅŸle."""
        
        # Robots.txt kontrolÃ¼
        if not self.check_robots_txt(url):
            return {'error': 'robots.txt tarafÄ±ndan engellendi'}
        
        # SayfayÄ± indir
        response = self.session.get(url, timeout=30)
        response.raise_for_status()
        
        # Ana iÃ§eriÄŸi Ã§Ä±kar (reklam, menÃ¼ vs. hariÃ§)
        text = trafilatura.extract(response.text)
        
        if not text:
            # Fallback: BeautifulSoup
            soup = BeautifulSoup(response.text, 'html.parser')
            # Script ve style'larÄ± kaldÄ±r
            for tag in soup(['script', 'style', 'nav', 'footer']):
                tag.decompose()
            text = soup.get_text(separator='\n', strip=True)
        
        # Metadata
        soup = BeautifulSoup(response.text, 'html.parser')
        title = soup.title.string if soup.title else urlparse(url).path
        
        # RAG'a ekle
        result = self.rag.add_text(
            text=text,
            metadata={
                'source': 'web',
                'url': url,
                'title': title,
                'crawled_at': datetime.now().isoformat()
            }
        )
        
        # Crawl depth > 0 ise linkleri takip et
        if crawl_depth > 0:
            links = self.extract_links(response.text, url)
            for link in links[:10]:  # Max 10 link
                self.load_url(link, crawl_depth - 1)
        
        return result
    
    def load_pdf_url(self, url: str) -> dict:
        """PDF URL'sini indir ve iÅŸle."""
        
        response = self.session.get(url, timeout=60)
        response.raise_for_status()
        
        # GeÃ§ici dosyaya kaydet
        temp_path = f"/tmp/{hashlib.md5(url.encode()).hexdigest()}.pdf"
        with open(temp_path, 'wb') as f:
            f.write(response.content)
        
        # RAG'a ekle
        result = self.rag.add_document(
            temp_path,
            metadata={'source': 'web', 'url': url}
        )
        
        # Temp dosyayÄ± sil
        os.remove(temp_path)
        
        return result
    
    def check_robots_txt(self, url: str) -> bool:
        """robots.txt kurallarÄ±nÄ± kontrol et."""
        from urllib.robotparser import RobotFileParser
        
        parsed = urlparse(url)
        robots_url = f"{parsed.scheme}://{parsed.netloc}/robots.txt"
        
        rp = RobotFileParser()
        rp.set_url(robots_url)
        try:
            rp.read()
            return rp.can_fetch('MyChatbot', url)
        except:
            return True  # robots.txt yoksa izin ver
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 1-2 gÃ¼n
- Test: 0.5 gÃ¼n

---

## 8. â° Zaman BazlÄ± Sorgulama

### AÃ§Ä±klama
DÃ¶kÃ¼manlarÄ± tarih/zaman bilgisine gÃ¶re filtreleme. "GeÃ§en yÄ±l", "son 3 ayda", "2022'de" gibi sorgular.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "2022 raporunda gelir ne kadardÄ±?"
AI: "2022 YÄ±llÄ±k Raporu'na gÃ¶re toplam gelir 5.2 milyon TL idi."

KullanÄ±cÄ±: "2023 ile karÅŸÄ±laÅŸtÄ±r"
AI: "2022 â†’ 2023 karÅŸÄ±laÅŸtÄ±rmasÄ±:
     - Gelir: 5.2M â†’ 6.8M (+30%)
     - Gider: 4.1M â†’ 4.5M (+10%)
     - KÃ¢r: 1.1M â†’ 2.3M (+109%)"

KullanÄ±cÄ±: "Son 3 yÄ±lÄ±n trendini gÃ¶ster"
AI: "[Grafik aÃ§Ä±klamasÄ±] Gelir sÃ¼rekli artÄ±ÅŸ trendinde..."
```

### Teknik Gereksinimler
- **Date Extraction**: DÃ¶kÃ¼manlardan tarih Ã§Ä±karma
- **Date Parser**: DoÄŸal dil tarih ifadelerini parse etme
- **Time Filter**: Metadata'da tarih filtresi

### Uygulama AdÄ±mlarÄ±
```python
from dateutil import parser as date_parser
from dateutil.relativedelta import relativedelta
import re

class TemporalRAG:
    def __init__(self, rag_pipeline):
        self.rag = rag_pipeline
    
    def parse_time_expression(self, query: str) -> dict:
        """DoÄŸal dil zaman ifadesini parse et."""
        
        now = datetime.now()
        
        patterns = {
            r'(\d{4})(?:\s*yÄ±lÄ±)?': lambda m: {
                'start': datetime(int(m.group(1)), 1, 1),
                'end': datetime(int(m.group(1)), 12, 31)
            },
            r'geÃ§en\s*yÄ±l': lambda m: {
                'start': datetime(now.year - 1, 1, 1),
                'end': datetime(now.year - 1, 12, 31)
            },
            r'son\s*(\d+)\s*ay': lambda m: {
                'start': now - relativedelta(months=int(m.group(1))),
                'end': now
            },
            r'son\s*(\d+)\s*yÄ±l': lambda m: {
                'start': now - relativedelta(years=int(m.group(1))),
                'end': now
            },
            r'bu\s*yÄ±l': lambda m: {
                'start': datetime(now.year, 1, 1),
                'end': now
            },
        }
        
        for pattern, handler in patterns.items():
            match = re.search(pattern, query.lower())
            if match:
                return handler(match)
        
        return None
    
    def search_with_time(self, query: str, top_k: int = 5) -> list:
        """Zaman filtreli arama."""
        
        time_range = self.parse_time_expression(query)
        
        if time_range:
            # Metadata filtresi oluÅŸtur
            filter_dict = {
                'document_date': {
                    '$gte': time_range['start'].isoformat(),
                    '$lte': time_range['end'].isoformat()
                }
            }
            return self.rag.search(query, top_k=top_k, filter=filter_dict)
        else:
            return self.rag.search(query, top_k=top_k)
    
    def extract_document_date(self, text: str, filename: str) -> datetime:
        """DÃ¶kÃ¼man tarihini Ã§Ä±kar."""
        
        # 1. Dosya adÄ±ndan
        year_match = re.search(r'(20\d{2})', filename)
        if year_match:
            return datetime(int(year_match.group(1)), 1, 1)
        
        # 2. Ä°Ã§erikten
        date_patterns = [
            r'Tarih:\s*(\d{1,2}[./]\d{1,2}[./]\d{4})',
            r'(\d{1,2}\s+\w+\s+\d{4})',
            r'(\d{4})\s*(?:YÄ±lÄ±|yÄ±lÄ±|YILI)',
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    return date_parser.parse(match.group(1), dayfirst=True)
                except:
                    continue
        
        return None
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 1-2 gÃ¼n
- Test: 0.5 gÃ¼n

---

## 9. ğŸ¯ Kaynak GÃ¼venilirlik Skoru

### AÃ§Ä±klama
FarklÄ± kaynaklarÄ±n gÃ¼venilirliÄŸini skorlama ve kullanÄ±cÄ±ya gÃ¶sterme. Resmi dÃ¶kÃ¼man vs blog yazÄ±sÄ± vs forum mesajÄ±.

### KullanÄ±m Senaryosu
```
KullanÄ±cÄ±: "Python'da memory leak nasÄ±l Ã¶nlenir?"

AI: "Bu konuda 3 farklÄ± kaynaktan bilgi buldum:

ğŸ“— **Python Resmi DÃ¶kÃ¼mantasyonu** (GÃ¼venilirlik: %95)
   gc modÃ¼lÃ¼ ve weakref kullanÄ±mÄ± Ã¶neriliyor.

ğŸ“˜ **Real Python Blog** (GÃ¼venilirlik: %80)
   Profiling araÃ§larÄ± ve best practice'ler anlatÄ±lmÄ±ÅŸ.

ğŸ“• **Stack Overflow CevabÄ±** (GÃ¼venilirlik: %60)
   Topluluk tarafÄ±ndan onaylanmÄ±ÅŸ pratik Ã§Ã¶zÃ¼mler.

âš ï¸ Not: Resmi dÃ¶kÃ¼mantasyonu temel almanÄ±zÄ± Ã¶neririm."
```

### Teknik Gereksinimler
- **Source Classification**: Kaynak tipini belirleme
- **Credibility Scoring**: GÃ¼venilirlik puanlama
- **Cross-reference**: Ã‡apraz doÄŸrulama

### Uygulama AdÄ±mlarÄ±
```python
class SourceCredibility:
    # Kaynak tipi skorlarÄ±
    SOURCE_SCORES = {
        'official_docs': 0.95,      # Resmi dÃ¶kÃ¼mantasyon
        'academic_paper': 0.90,     # Akademik makale
        'technical_book': 0.85,     # Teknik kitap
        'reputable_blog': 0.75,     # GÃ¼venilir blog
        'tutorial': 0.70,           # Tutorial
        'forum_accepted': 0.65,     # Kabul edilen forum cevabÄ±
        'blog_post': 0.55,          # Blog yazÄ±sÄ±
        'forum_post': 0.40,         # Forum mesajÄ±
        'unknown': 0.30,            # Bilinmeyen kaynak
    }
    
    # Domain bazlÄ± gÃ¼venilirlik
    TRUSTED_DOMAINS = {
        'docs.python.org': 'official_docs',
        'developer.mozilla.org': 'official_docs',
        'arxiv.org': 'academic_paper',
        'realpython.com': 'reputable_blog',
        'stackoverflow.com': 'forum_accepted',
    }
    
    def __init__(self):
        self.cross_reference_cache = {}
    
    def calculate_credibility(self, chunk: dict) -> float:
        """Chunk iÃ§in gÃ¼venilirlik skoru hesapla."""
        
        metadata = chunk.get('metadata', {})
        
        # 1. Kaynak tipi skoru
        source_type = self.classify_source(metadata)
        base_score = self.SOURCE_SCORES.get(source_type, 0.30)
        
        # 2. Ã‡apraz doÄŸrulama bonusu
        cross_ref_bonus = self.check_cross_reference(chunk['text'])
        
        # 3. Tarih cezasÄ± (eski iÃ§erik)
        date_penalty = self.calculate_date_penalty(metadata.get('date'))
        
        # 4. Final skor
        final_score = min(1.0, base_score + cross_ref_bonus - date_penalty)
        
        return round(final_score, 2)
    
    def classify_source(self, metadata: dict) -> str:
        """KaynaÄŸÄ± sÄ±nÄ±flandÄ±r."""
        
        url = metadata.get('url', '')
        file_type = metadata.get('file_type', '')
        
        # URL'den domain kontrolÃ¼
        for domain, source_type in self.TRUSTED_DOMAINS.items():
            if domain in url:
                return source_type
        
        # Dosya tipine gÃ¶re
        if file_type == 'pdf':
            if 'academic' in metadata.get('title', '').lower():
                return 'academic_paper'
            return 'technical_book'
        
        return 'unknown'
    
    def check_cross_reference(self, text: str) -> float:
        """Ã‡apraz doÄŸrulama - aynÄ± bilgi baÅŸka kaynaklarda var mÄ±?"""
        
        # Basit implementasyon: aynÄ± anahtar kavramlar kaÃ§ kaynakta geÃ§iyor
        # GerÃ§ek implementasyonda semantic similarity kullanÄ±lÄ±r
        
        # Bonus: 0 - 0.15 arasÄ±
        return 0.0
    
    def calculate_date_penalty(self, date_str: str) -> float:
        """Eski iÃ§erik cezasÄ±."""
        
        if not date_str:
            return 0.05  # Tarih yoksa kÃ¼Ã§Ã¼k ceza
        
        try:
            doc_date = date_parser.parse(date_str)
            age_years = (datetime.now() - doc_date).days / 365
            
            if age_years > 5:
                return 0.15
            elif age_years > 2:
                return 0.05
            return 0
        except:
            return 0.05
    
    def format_credibility_display(self, score: float) -> str:
        """GÃ¼venilirlik skorunu gÃ¶rsel formatta gÃ¶ster."""
        
        percentage = int(score * 100)
        
        if score >= 0.9:
            emoji = "ğŸ“—"
            label = "Ã‡ok GÃ¼venilir"
        elif score >= 0.7:
            emoji = "ğŸ“˜"
            label = "GÃ¼venilir"
        elif score >= 0.5:
            emoji = "ğŸ“™"
            label = "Orta"
        else:
            emoji = "ğŸ“•"
            label = "DÃ¼ÅŸÃ¼k"
        
        return f"{emoji} {label} (%{percentage})"
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 1-2 gÃ¼n
- Test: 0.5 gÃ¼n

---

## 10. ğŸ’¡ Otomatik Soru Ã–nerisi

### AÃ§Ä±klama
DÃ¶kÃ¼man yÃ¼klendikten sonra "Bu dÃ¶kÃ¼man hakkÄ±nda ÅŸunlarÄ± sorabilirsiniz" ÅŸeklinde akÄ±llÄ± soru Ã¶nerileri.

### KullanÄ±m Senaryosu
```
[KullanÄ±cÄ± "sÃ¶zleÅŸme.pdf" yÃ¼kledi]

AI: "âœ… SÃ¶zleÅŸme baÅŸarÄ±yla yÃ¼klendi!

ğŸ’¡ Bu dÃ¶kÃ¼man hakkÄ±nda sorabilecekleriniz:
1. SÃ¶zleÅŸmenin sÃ¼resi ne kadar?
2. AylÄ±k/yÄ±llÄ±k Ã¼cret ne kadar?
3. Fesih koÅŸullarÄ± neler?
4. TaraflarÄ±n yÃ¼kÃ¼mlÃ¼lÃ¼kleri neler?
5. Gizlilik maddeleri var mÄ±?

ğŸ“Š DÃ¶kÃ¼man Ã¶zellikleri:
- 12 sayfa
- TÃ¼rkÃ§e
- Hizmet sÃ¶zleÅŸmesi"
```

### Teknik Gereksinimler
- **Content Analysis**: DÃ¶kÃ¼man iÃ§eriÄŸini analiz etme
- **Question Generation**: Ä°Ã§erikten soru Ã¼retme
- **Document Classification**: DÃ¶kÃ¼man tipini belirleme

### Uygulama AdÄ±mlarÄ±
```python
class QuestionSuggester:
    # DÃ¶kÃ¼man tipi bazlÄ± soru ÅŸablonlarÄ±
    QUESTION_TEMPLATES = {
        'contract': [
            "SÃ¶zleÅŸmenin sÃ¼resi ne kadar?",
            "Taraflar kimler?",
            "Ãœcret/bedel ne kadar?",
            "Fesih koÅŸullarÄ± neler?",
            "Ceza maddeleri var mÄ±?",
        ],
        'report': [
            "Raporun ana bulgularÄ± neler?",
            "Hangi dÃ¶nem ele alÄ±nmÄ±ÅŸ?",
            "Ã–neriler neler?",
            "SonuÃ§ ve deÄŸerlendirme ne?",
        ],
        'manual': [
            "Temel Ã¶zellikler neler?",
            "NasÄ±l kurulur/baÅŸlatÄ±lÄ±r?",
            "SÄ±k karÅŸÄ±laÅŸÄ±lan sorunlar neler?",
            "Teknik Ã¶zellikler neler?",
        ],
        'academic': [
            "Ã‡alÄ±ÅŸmanÄ±n amacÄ± ne?",
            "KullanÄ±lan metodoloji ne?",
            "Ana bulgular neler?",
            "SonuÃ§ ve Ã¶neriler neler?",
        ],
        'default': [
            "Bu dÃ¶kÃ¼man ne hakkÄ±nda?",
            "Ana konular neler?",
            "Ã–nemli noktalar neler?",
        ]
    }
    
    def __init__(self, rag_pipeline):
        self.rag = rag_pipeline
    
    def classify_document(self, text: str, filename: str) -> str:
        """DÃ¶kÃ¼man tipini belirle."""
        
        text_lower = text.lower()
        
        # Anahtar kelime bazlÄ± sÄ±nÄ±flandÄ±rma
        if any(w in text_lower for w in ['sÃ¶zleÅŸme', 'taraflar', 'madde', 'yÃ¼kÃ¼mlÃ¼lÃ¼k']):
            return 'contract'
        elif any(w in text_lower for w in ['rapor', 'bulgu', 'analiz', 'sonuÃ§']):
            return 'report'
        elif any(w in text_lower for w in ['kurulum', 'kullanÄ±m', 'Ã¶zellik', 'manual']):
            return 'manual'
        elif any(w in text_lower for w in ['abstract', 'methodology', 'references', 'Ã¶zet']):
            return 'academic'
        
        return 'default'
    
    def generate_questions(self, doc_id: str, max_questions: int = 5) -> list:
        """DÃ¶kÃ¼man iÃ§in soru Ã¶nerileri Ã¼ret."""
        
        # DÃ¶kÃ¼man iÃ§eriÄŸini al
        chunks = self.rag.get_all_chunks(doc_id)
        full_text = "\n".join([c['text'] for c in chunks[:5]])  # Ä°lk 5 chunk
        filename = self.rag.get_document_info(doc_id)['file_name']
        
        # DÃ¶kÃ¼man tipini belirle
        doc_type = self.classify_document(full_text, filename)
        
        # Åablon sorularÄ±nÄ± al
        template_questions = self.QUESTION_TEMPLATES.get(doc_type, self.QUESTION_TEMPLATES['default'])
        
        # LLM ile dÃ¶kÃ¼man-spesifik sorular Ã¼ret
        custom_questions = self.generate_custom_questions(full_text, doc_type)
        
        # BirleÅŸtir ve sÄ±nÄ±rla
        all_questions = template_questions + custom_questions
        return all_questions[:max_questions]
    
    def generate_custom_questions(self, text: str, doc_type: str) -> list:
        """LLM ile dÃ¶kÃ¼man-spesifik sorular Ã¼ret."""
        
        prompt = f"""
        AÅŸaÄŸÄ±daki {doc_type} dÃ¶kÃ¼manÄ± iÃ§in kullanÄ±cÄ±nÄ±n sorabileceÄŸi 
        3 spesifik soru Ã¶ner. DÃ¶kÃ¼man iÃ§eriÄŸine Ã¶zgÃ¼, genel olmayan sorular olsun.
        
        DÃ¶kÃ¼man (ilk kÄ±sÄ±m):
        {text[:2000]}
        
        Sadece sorularÄ± listele, baÅŸka bir ÅŸey yazma:
        1.
        2.
        3.
        """
        
        response = llm.complete(prompt)
        
        # Parse et
        questions = []
        for line in response.strip().split('\n'):
            line = line.strip()
            if line and line[0].isdigit():
                # "1. Soru" formatÄ±nÄ± temizle
                question = re.sub(r'^\d+\.\s*', '', line)
                questions.append(question)
        
        return questions
    
    def get_document_summary_with_questions(self, doc_id: str) -> dict:
        """DÃ¶kÃ¼man Ã¶zeti ve soru Ã¶nerileri."""
        
        doc_info = self.rag.get_document_info(doc_id)
        questions = self.generate_questions(doc_id)
        
        return {
            'file_name': doc_info['file_name'],
            'page_count': doc_info.get('page_count', 'N/A'),
            'chunk_count': doc_info.get('chunk_count', 0),
            'document_type': self.classify_document(
                self.rag.get_all_chunks(doc_id)[0]['text'],
                doc_info['file_name']
            ),
            'suggested_questions': questions,
            'message': f"âœ… {doc_info['file_name']} baÅŸarÄ±yla yÃ¼klendi!\n\nğŸ’¡ Bu dÃ¶kÃ¼man hakkÄ±nda sorabilecekleriniz:"
        }
```

### Tahmini SÃ¼re
- GeliÅŸtirme: 1 gÃ¼n
- Test: 0.5 gÃ¼n

---

## ğŸ“… Uygulama Ã–ncelik SÄ±rasÄ±

Ã–nerilen geliÅŸtirme sÄ±rasÄ± (baÄŸÄ±mlÄ±lÄ±klar ve etki gÃ¶z Ã¶nÃ¼nde):

### Faz 1 - Temel Ä°yileÅŸtirmeler (1 hafta)
1. âœ… Conversational RAG - En Ã§ok istenen Ã¶zellik
2. âœ… Otomatik Soru Ã–nerisi - KullanÄ±cÄ± deneyimi
3. âœ… Otomatik Ã–zet - HÄ±zlÄ± deÄŸer

### Faz 2 - GeliÅŸmiÅŸ Ã–zellikler (2 hafta)
4. Web URL'den DÃ¶kÃ¼man
5. Ã‡oklu DÃ¶kÃ¼man KarÅŸÄ±laÅŸtÄ±rma
6. Zaman BazlÄ± Sorgulama

### Faz 3 - Uzman Ã–zellikler (2-3 hafta)
7. Table QA
8. Semantik Kod Arama
9. Kaynak GÃ¼venilirlik Skoru

### Faz 4 - Ä°leri DÃ¼zey (3-4 hafta)
10. Multi-Modal RAG

---

## ğŸ› ï¸ Gerekli Ek KÃ¼tÃ¼phaneler

```txt
# requirements.txt'e eklenecekler

# Multi-Modal
pdf2image==1.16.3
pytesseract==0.3.10
Pillow>=10.0.0
# clip-by-openai  # Opsiyonel

# Table QA
tabula-py==2.9.0
openpyxl==3.1.2

# Web Scraping
trafilatura==1.6.0
beautifulsoup4==4.12.2

# Code Search
tree-sitter==0.21.0

# Date Parsing
python-dateutil==2.8.2
```

---

## ğŸ“ Notlar

- Her Ã¶zellik baÄŸÄ±msÄ±z olarak eklenebilir
- Mevcut RAG altyapÄ±sÄ± Ã¼zerine inÅŸa edilecek
- Test coverage minimum %80 hedefleniyor
- Her Ã¶zellik iÃ§in API endpoint'i eklenecek
- Frontend entegrasyonu ayrÄ± task olarak planlanacak
